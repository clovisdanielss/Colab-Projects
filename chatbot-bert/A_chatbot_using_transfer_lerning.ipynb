{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clovisdanielss/Colab-Projects/blob/main/chatbot-bert/A_chatbot_using_transfer_lerning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN39qplL3QPF",
        "outputId": "d7d41449-4cac-4d3c-c954-b15caf30e250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 9.5 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting tensorflowjs\n",
            "  Downloading tensorflowjs-3.17.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Collecting tensorflow<2.10,>=2.9.0\n",
            "  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 3.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.0.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.17.3)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.25.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.2)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (14.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.46.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.9)\n",
            "Collecting packaging\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-estimator, tensorboard, pyyaml, packaging, keras, gast, flatbuffers, tokenizers, tensorflow, huggingface-hub, transformers, tensorflowjs, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 huggingface-hub-0.6.0 keras-2.9.0 packaging-20.9 pyyaml-6.0 tensorboard-2.9.0 tensorflow-2.9.0 tensorflow-estimator-2.9.0 tensorflow-text-2.9.0 tensorflowjs-3.17.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text transformers tensorflowjs\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from transformers import TFBertModel\n",
        "from transformers import BertTokenizerFast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li8XC7nUBJ-x"
      },
      "source": [
        "### Defining our encoding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XgCfeiYv83_a"
      },
      "outputs": [],
      "source": [
        "preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/2\")\n",
        "max_len=128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "input_type_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")"
      ],
      "metadata": {
        "id": "fPXTFfmx5clQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C7kygP2JACh7"
      },
      "outputs": [],
      "source": [
        "encoder_output = encoder({\"input_mask\":input_mask, \"input_type_ids\":input_type_ids, \"input_word_ids\":input_word_ids})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loT5FrAQAHfU",
        "outputId": "c1ed8bdb-5132-4c6a-d868-4cc1c32cca2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'default': <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              " 'encoder_outputs': [<KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              "  <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>],\n",
              " 'pooled_output': <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'keras_layer_1')>,\n",
              " 'sequence_output': <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'keras_layer_1')>}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "encoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IMVRkLRi_Y78"
      },
      "outputs": [],
      "source": [
        "model_encoder = tf.keras.models.Model(inputs={\"input_mask\":input_mask, \"input_type_ids\":input_type_ids, \"input_word_ids\":input_word_ids},\n",
        "                                      outputs=encoder_output[\"sequence_output\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_encoder(preprocess([\"hello\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEqAImqY8i9g",
        "outputId": "446800b9-0ea5-4b15-f16d-d3630a7c5b51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 128, 128), dtype=float32, numpy=\n",
              "array([[[-0.6293698 ,  0.330106  ,  0.5830009 , ..., -1.0687764 ,\n",
              "         -0.24665578, -0.41392398],\n",
              "        [-0.09322161, -0.04189947,  0.18499213, ..., -2.1253293 ,\n",
              "          0.532886  , -0.5445148 ],\n",
              "        [-1.3539305 ,  0.7147312 ,  0.49062362, ...,  0.02443573,\n",
              "          0.46058017, -0.77477443],\n",
              "        ...,\n",
              "        [-1.3059756 ,  0.28991982,  0.24231845, ..., -2.138464  ,\n",
              "         -0.24562147, -0.507223  ],\n",
              "        [-1.2509861 ,  0.3879781 ,  0.40541792, ..., -1.9272692 ,\n",
              "          0.05003832, -0.92508066],\n",
              "        [-0.30739072,  0.42505884,  0.09383105, ..., -1.5127901 ,\n",
              "          0.45798174, -0.6818999 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QdgNX2Ap_55X"
      },
      "outputs": [],
      "source": [
        "model_encoder.treinable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crtYKXTDBNu_"
      },
      "source": [
        "### Defining our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4YkBnf3YAPwW",
        "outputId": "79ddffe1-8a1e-4163-9e4a-20e29aea2b79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             phrase   intent\n",
              "0                hi  WELCOME\n",
              "1  hi, how are you?  WELCOME\n",
              "2     Good morning?  WELCOME\n",
              "3  Good afternoon!!  WELCOME\n",
              "4      Good evening  WELCOME"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7030794-9a4d-4d20-9785-04aeaf073b93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>WELCOME</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi, how are you?</td>\n",
              "      <td>WELCOME</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Good morning?</td>\n",
              "      <td>WELCOME</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Good afternoon!!</td>\n",
              "      <td>WELCOME</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Good evening</td>\n",
              "      <td>WELCOME</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7030794-9a4d-4d20-9785-04aeaf073b93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7030794-9a4d-4d20-9785-04aeaf073b93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7030794-9a4d-4d20-9785-04aeaf073b93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data = {\n",
        "    \"phrase\":[\n",
        "          \"hi\",\n",
        "          \"hi, how are you?\",\n",
        "          \"Good morning?\",\n",
        "          \"Good afternoon!!\",\n",
        "          \"Good evening\",\n",
        "        \"See you\",\n",
        "        \"Bye\",\n",
        "        \"till later\",\n",
        "        \"Tomorrow we talk\",\n",
        "        \"see you later\",\n",
        "    ],\n",
        "    \"intent\":[\n",
        "        \"WELCOME\",\n",
        "        \"WELCOME\",\n",
        "        \"WELCOME\",\n",
        "        \"WELCOME\",\n",
        "        \"WELCOME\",\n",
        "        \"FAREWELL\",\n",
        "        \"FAREWELL\",\n",
        "        \"FAREWELL\",\n",
        "        \"FAREWELL\",\n",
        "        \"FAREWELL\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "data = pd.DataFrame(data)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv_93kMECa97",
        "outputId": "237e38c2-dbfe-42be-e5de-7a864a95c818"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, (2,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "intents =  data.intent.unique()\n",
        "intent_encoder = lambda intent: np.where(intents == intent)[0][0]\n",
        "intent_encoder(\"WELCOME\"), intents.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EFXGeCSqEJSO",
        "outputId": "0ef35798-3b6e-41cd-df22-53fb2ca4c65f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             phrase   intent  intent_encoded\n",
              "0                hi  WELCOME               0\n",
              "1  hi, how are you?  WELCOME               0\n",
              "2     Good morning?  WELCOME               0\n",
              "3  Good afternoon!!  WELCOME               0\n",
              "4      Good evening  WELCOME               0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eab2023b-733b-4ed9-8a8d-9ac8a37e543e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>intent</th>\n",
              "      <th>intent_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>WELCOME</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi, how are you?</td>\n",
              "      <td>WELCOME</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Good morning?</td>\n",
              "      <td>WELCOME</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Good afternoon!!</td>\n",
              "      <td>WELCOME</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Good evening</td>\n",
              "      <td>WELCOME</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eab2023b-733b-4ed9-8a8d-9ac8a37e543e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eab2023b-733b-4ed9-8a8d-9ac8a37e543e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eab2023b-733b-4ed9-8a8d-9ac8a37e543e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data[\"intent_encoded\"] = data.intent.map(intent_encoder)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGLnEPZJFIRV",
        "outputId": "b5f620fe-31ca-4e83-967b-6d1dbe28fa12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['hi', 'hi, how are you?', 'Good morning?', 'Good afternoon!!',\n",
              "        'Good evening', 'See you', 'Bye', 'till later', 'Tomorrow we talk',\n",
              "        'see you later'], dtype=object), array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x = data.phrase.to_numpy()\n",
        "y = data.intent_encoded.to_numpy()\n",
        "x,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUcC1hUCFtzN"
      },
      "source": [
        "### Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gKA9t_7WK6sJ"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCmgKQ8uFq3O",
        "outputId": "07872e28-94ee-48d2-bd3f-842dec6f77b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 13s 13s/step - loss: 35.8494 - accuracy: 0.6000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 381ms/step - loss: 0.3228 - accuracy: 0.9000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 3.0485 - accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.3804 - accuracy: 0.9000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 0.3979 - accuracy: 0.8000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 0.4799 - accuracy: 0.6000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.5661 - accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 403ms/step - loss: 0.6469 - accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 415ms/step - loss: 0.7046 - accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 0.7234 - accuracy: 0.6000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 0.6383 - accuracy: 0.6000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.5525 - accuracy: 0.6000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.4558 - accuracy: 0.8000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.4185 - accuracy: 0.8000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 0.3724 - accuracy: 0.7000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.3379 - accuracy: 0.8000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 373ms/step - loss: 0.3272 - accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 383ms/step - loss: 0.3296 - accuracy: 0.9000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.3252 - accuracy: 0.9000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 0.3084 - accuracy: 0.9000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0d2cd8d90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "layer_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation=\"relu\"))(encoder_output[\"sequence_output\"])\n",
        "layer_dense = tf.keras.layers.Dense(intents.shape[0], activation=\"softmax\")(layer_lstm)\n",
        "\n",
        "model = tf.keras.models.Model(inputs={\"input_mask\":input_mask, \"input_type_ids\":input_type_ids, \"input_word_ids\":input_word_ids},\n",
        "                                      outputs=layer_dense)\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(preprocess(x),y, epochs=20, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tJarUtnKvBv",
        "outputId": "9f828b4e-ed15-4eb6-e3bc-27bad76fb42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.927416, 0.072584]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model.predict(preprocess([\"Olá! Howdy ?\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4S3yIbrKovK",
        "outputId": "7f449d30-6808-4815-e3f7-92e2de375a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.8977 - accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.6598 - accuracy: 0.4000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.5279 - accuracy: 0.8000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.4240 - accuracy: 0.9000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.3416 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.2835 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 406ms/step - loss: 0.2358 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.1909 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 388ms/step - loss: 0.1505 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.1180 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 395ms/step - loss: 0.0916 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 1s 621ms/step - loss: 0.0704 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 420ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 414ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 390ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.0083 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0d7e1c350>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "layer_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(encoder_output[\"sequence_output\"])\n",
        "layer_dense = tf.keras.layers.Dense(intents.shape[0], activation=\"softmax\")(layer_lstm)\n",
        "\n",
        "model = tf.keras.models.Model(inputs={\"input_mask\":input_mask, \"input_type_ids\":input_type_ids, \"input_word_ids\":input_word_ids},\n",
        "                                      outputs=layer_dense)\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(preprocess(x),y, epochs=20, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9C5aRhoGyVY",
        "outputId": "e8b54a59-4904-456d-c102-2b4a8c935f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9884925, 0.0115075]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model.predict(preprocess([\"Olá! Howdy ?\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG8mjqVkQ0QD"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "When using tanh, the LSTM layer reduce the loss, so the probability difference between classes are greater. \n",
        "\n",
        "Unfortunely the keras layer from Tf_hub presents operations that we cannot use in tensorflowjs. \n",
        "\n",
        "So we wont use the above model. We will use bert, but from another library. \n",
        "\n",
        "Also we wont export the preprocessing layer, because this layer have operations that we wont support in tensorflowjs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "444JrQnwPNkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89cb04b8-6614-40a5-d784-169db614075a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 80). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ./model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ./model/assets\n"
          ]
        }
      ],
      "source": [
        "def create_model(max_len, classifier_layer=True):\n",
        "    # Load tiny BERT model\n",
        "    encoder = TFBertModel.from_pretrained(\n",
        "        \"google/bert_uncased_L-2_H-128_A-2\", from_pt=True)\n",
        "\n",
        "    # Setup input layer\n",
        "    input_ids = tf.keras.layers.Input(\n",
        "        shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "    token_type_ids = tf.keras.layers.Input(\n",
        "        shape=(max_len,), dtype=tf.int32, name=\"token_type_ids\")\n",
        "    attention_mask = tf.keras.layers.Input(\n",
        "        shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "    bert = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "\n",
        "    # Make sure BERT weights stay the same during training\n",
        "    bert.trainable = False\n",
        "\n",
        "    # For python training we add a classification layer\n",
        "    if classifier_layer:\n",
        "        bert = tf.keras.layers.Dense(1, activation=\"sigmoid\")(bert)\n",
        "\n",
        "\n",
        "    # Put model together\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[bert],\n",
        "    )\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss=[loss], metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Model takes 128 tokens as input\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Save model for TFJS\n",
        "model_to_save = create_model(MAX_LEN, False)\n",
        "model_to_save.save(\"./model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Just to we understand, we can check the output from the Bert model in transformers. \n",
        "\n"
      ],
      "metadata": {
        "id": "NmFFOZVCO9Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TFBertModel.from_pretrained(\n",
        "        \"google/bert_uncased_L-2_H-128_A-2\", from_pt=True)\n",
        "\n",
        "    # Setup input layer\n",
        "input_ids = tf.keras.layers.Input(\n",
        "        shape=(128,), dtype=tf.int32, name=\"input_ids\")\n",
        "token_type_ids = tf.keras.layers.Input(\n",
        "        shape=(128,), dtype=tf.int32, name=\"token_type_ids\")\n",
        "attention_mask = tf.keras.layers.Input(\n",
        "        shape=(128,), dtype=tf.int32, name=\"attention_mask\")\n",
        "bert = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        ")\n",
        "bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJvUl0zNO7yx",
        "outputId": "778de059-da70-4ddc-9576-3e597dca3e5e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                                 <KerasTensor: shape=(None, 128, 128) dtype=float32 (created by layer 'tf_bert_model_4')>),\n",
              "                                                ('pooler_output',\n",
              "                                                 <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'tf_bert_model_4')>)])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### As you can see\n",
        "The output from here is similar to the pooling_output and the sequence_output from the tf_hub bert model."
      ],
      "metadata": {
        "id": "S3QZsWJ_Qd4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model model tfjs_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak63jFMhDqgM",
        "outputId": "cc17660d-2b22-479d-b1d1-237ac5a1f9f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-22 19:33:45.871704: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Writing weight file tfjs_model/model.json...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess([\"hello\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOclZeI7Qw3Y",
        "outputId": "0af438ec-235d-474f-bba9-10effa64113e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_mask': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              " array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "       dtype=int32)>,\n",
              " 'input_type_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "       dtype=int32)>,\n",
              " 'input_word_ids': <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              " array([[ 101, 7592,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also the inputs are somewhat equal. But, we have different indexes. \n",
        "So if we map correctly, we can get the output from the sequence model."
      ],
      "metadata": {
        "id": "CIO7RjH1Q5eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = preprocess([\"hello\"])\n",
        "model_to_save({\"input_ids\":input[\"input_word_ids\"], \"token_type_ids\":input[\"input_type_ids\"], \"attention_mask\":input[\"input_mask\"]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl8JH3MlREJI",
        "outputId": "5336a3c3-dc52-4593-eb17-9d73634422b0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 128, 128), dtype=float32, numpy=\n",
              "array([[[-0.7593664 ,  0.5279064 , -2.5522919 , ..., -0.91000545,\n",
              "         -1.1436156 ,  0.30035463],\n",
              "        [-1.689142  ,  0.5541231 , -1.0885587 , ..., -2.1692183 ,\n",
              "         -1.7289025 ,  0.6991626 ],\n",
              "        [-2.0604274 ,  0.641974  , -0.9092632 , ..., -1.609783  ,\n",
              "         -0.97651625,  1.3083776 ],\n",
              "        ...,\n",
              "        [-0.8173223 ,  0.2380738 , -0.9260769 , ..., -1.2405076 ,\n",
              "         -1.230954  ,  1.1262554 ],\n",
              "        [-0.46505487,  0.27091733, -0.9593175 , ..., -1.1374489 ,\n",
              "         -1.2489855 ,  1.0026721 ],\n",
              "        [-0.28894883,  0.38519603, -0.9330457 , ..., -1.012916  ,\n",
              "         -1.4600381 ,  0.8929069 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!zip -r ./model.zip ./tfjs_model\n",
        "files.download(\"model.zip\")"
      ],
      "metadata": {
        "id": "7hfLAopPCyHX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "A chatbot using transfer lerning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP6CyyZQckvX0B0d5s8rhVg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}